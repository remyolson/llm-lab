[build-system]
requires = ["setuptools>=45", "wheel", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "lllm-lab"
description = "Comprehensive LLM Provider Testing and Benchmarking Suite"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "LLM Lab", email = "contact@lllm-lab.dev"}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Software Development :: Testing",
    "Topic :: Scientific/Engineering :: Artificial Intelligence"
]
requires-python = ">=3.9"
dependencies = [
    "openai>=1.0.0",
    "anthropic>=0.18.0",
    "google-generativeai>=0.3.0",
    "requests>=2.28.0",
    "pydantic>=2.0.0",
    "python-dotenv>=1.0.0",
]
dynamic = ["version"]

[project.optional-dependencies]
test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "pytest-xdist>=3.0.0",
    "pytest-mock>=3.10.0",
    "pytest-asyncio>=0.21.0",
    "coverage[toml]>=7.0.0",
]
benchmarks = [
    "matplotlib>=3.6.0",
    "seaborn>=0.12.0",
    "pandas>=1.5.0",
    "psutil>=5.9.0",
    "numpy>=1.24.0",
]
security = [
    "bandit>=1.7.0",
    "safety>=2.0.0",
    "semgrep>=1.0.0",
]
dev = [
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0",
    "pre-commit>=3.0.0",
]
all = [
    "lllm-lab[test,benchmarks,security,dev]"
]

[project.urls]
Homepage = "https://github.com/user/lllm-lab"
Repository = "https://github.com/user/lllm-lab"
Documentation = "https://lllm-lab.readthedocs.io"
"Bug Tracker" = "https://github.com/user/lllm-lab/issues"

[project.scripts]
lllm-benchmark = "tests.performance.demo_performance_suite:main"
lllm-compatibility = "tests.compatibility.demo_compatibility_suite:main"
lllm-integration = "tests.integration.demo_integration_framework:main"

[tool.setuptools_scm]

[tool.coverage.run]
source = ["llm_providers", "tests"]
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/venv/*",
    "*/env/*",
    "*/.venv/*",
    "setup.py",
    "conftest.py",
]
branch = true
parallel = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
    "class .*\\(Protocol\\):",
    "@overload",
]
show_missing = true
skip_covered = false
skip_empty = false
precision = 2
fail_under = 75

[tool.coverage.html]
directory = "htmlcov"
show_contexts = true

[tool.coverage.xml]
output = "coverage.xml"

[tool.pytest.ini_options]
minversion = "7.0"
addopts = [
    "-ra",
    "--strict-markers",
    "--strict-config",
    "--cov=llm_providers",
    "--cov=tests",
    "--cov-branch",
    "--cov-report=term-missing:skip-covered",
    "--cov-fail-under=75",
]
testpaths = ["tests"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "compatibility: marks tests as compatibility tests",
    "performance: marks tests as performance benchmarks",
    "unit: marks tests as unit tests",
    "openai: marks tests that require OpenAI API",
    "anthropic: marks tests that require Anthropic API",
    "google: marks tests that require Google API",
    "requires_api: marks tests that require API access",
    "expensive: marks tests that consume significant API quota",
]
filterwarnings = [
    "error",
    "ignore::UserWarning",
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
]
log_cli = true
log_cli_level = "INFO"
log_cli_format = "%(asctime)s [%(levelname)8s] %(name)s: %(message)s"
log_cli_date_format = "%Y-%m-%d %H:%M:%S"

[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 100
known_first_party = ["llm_providers", "tests"]
known_third_party = ["pytest", "openai", "anthropic", "google"]
sections = ["FUTURE", "STDLIB", "THIRDPARTY", "FIRSTPARTY", "LOCALFOLDER"]
combine_as_imports = true
force_grid_wrap = 0
include_trailing_comma = true
use_parentheses = true

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_incomplete_defs = false
check_untyped_defs = true
disallow_untyped_decorators = false
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
show_error_codes = true
show_column_numbers = true
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = [
    "tests.*",
    "conftest",
]
ignore_errors = true

[tool.bandit]
exclude_dirs = ["tests", "test_*"]
skips = ["B101", "B601"]  # Skip assert_used and shell injection in tests

[tool.flake8]
max-line-length = 100
extend-ignore = ["E203", "W503", "E501"]
exclude = [
    ".git",
    "__pycache__",
    "build",
    "dist",
    "*.egg-info",
    ".venv",
    "venv",
]
per-file-ignores = [
    "__init__.py:F401",
    "tests/*:F401,F811,F403,F405",
]