name: instruction_tuning_alpaca
description: Recipe for instruction tuning using Alpaca-style dataset format
version: 1.0.0
author: llm-lab
tags:
  - instruction-tuning
  - alpaca
  - general-purpose

model:
  name: llama2-7b-instruct
  base_model: meta-llama/Llama-2-7b-hf
  model_type: causal_lm
  quantization: null
  device_map: auto
  torch_dtype: float16
  load_in_8bit: false
  load_in_4bit: false
  use_flash_attention: true

dataset:
  name: alpaca_dataset
  path: yahma/alpaca-cleaned  # Can be local path or HuggingFace dataset
  format: huggingface
  data_format: alpaca
  split_ratios:
    train: 0.9
    validation: 0.05
    test: 0.05
  max_samples: null  # Use all samples
  preprocessing:
    lowercase: false
    remove_html: true
    normalize_whitespace: true
    add_prompt_template: true
  tokenizer_config:
    max_length: 512
    padding: max_length
    truncation: true

training:
  num_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-5
  warmup_steps: 100
  weight_decay: 0.01
  logging_steps: 10
  eval_steps: 500
  save_steps: 1000
  save_total_limit: 3
  fp16: true
  bf16: false
  gradient_checkpointing: true
  deepspeed_config: null
  fsdp_config: null
  
  # LoRA configuration
  use_lora: true
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.05
  lora_target_modules:
    - q_proj
    - v_proj
    - k_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj

evaluation:
  metrics:
    - perplexity
    - bleu
    - rouge
    - exact_match
  benchmarks:
    - mmlu
    - hellaswag
  custom_metrics: {}
  eval_batch_size: 8
  num_beams: 4
  temperature: 0.7
  top_k: 50
  top_p: 0.95

metadata:
  recommended_hardware: "16GB+ VRAM GPU or Apple Silicon with 16GB+ RAM"
  estimated_training_time: "2-4 hours on A100"
  use_case: "General instruction following and task completion"
  notes: |
    This recipe is optimized for the Alpaca dataset format with columns:
    - instruction: The task description
    - input: Optional context or input data
    - output: The expected response
    
    The model will learn to follow diverse instructions and generate
    appropriate responses.