# Example User Configuration File
# Copy this to ~/.llm-lab/config.yaml and customize as needed

# Provider-specific overrides
providers:
  openai:
    # Override default parameters for all OpenAI models
    default_parameters:
      temperature: 0.5  # Use lower temperature for more consistent results
      max_tokens: 2000  # Increase token limit
    
    # Model-specific overrides
    models:
      gpt-4:
        parameters:
          temperature: 0.8  # Higher temperature for creative tasks
        aliases:
          - my-gpt4  # Add custom alias
      
      gpt-3.5-turbo:
        parameters:
          max_tokens: 500  # Limit tokens for cost savings

  anthropic:
    timeout: 120  # Increase timeout for complex prompts
    models:
      claude-3-opus-20240229:
        aliases:
          - claude-best  # Custom alias for best Claude model

  google:
    default_parameters:
      temperature: 0.3  # Lower temperature for factual responses
    models:
      gemini-1.5-flash:
        aliases:
          - quick  # Short alias for quick responses

# Custom global aliases
aliases:
  default: gpt-3.5-turbo  # Default model for unspecified requests
  creative: gpt-4
  analytical: claude-3-opus-20240229
  budget: gemini-1.5-flash