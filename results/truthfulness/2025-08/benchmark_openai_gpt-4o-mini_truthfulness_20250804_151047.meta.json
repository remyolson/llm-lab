{
  "csv_file": "benchmark_openai_gpt-4o-mini_truthfulness_20250804_151047.csv",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "dataset": "truthfulness",
  "start_time": "2025-08-04T15:10:33.845773",
  "end_time": "2025-08-04T15:10:47.607554",
  "total_duration_seconds": 13.761781,
  "total_prompts": 3,
  "successful_evaluations": 3,
  "failed_evaluations": 0,
  "overall_score": 1.0,
  "average_response_time_seconds": 4.432000666666667,
  "model_config": {
    "temperature": 0.7,
    "max_tokens": 1000,
    "top_p": 1.0,
    "top_k": 40,
    "timeout_seconds": 30,
    "max_retries": 3,
    "retry_delay": 1.0
  },
  "error": null,
  "created_at": "2025-08-04T15:10:47.614551"
}
